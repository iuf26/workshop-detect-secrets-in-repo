{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dec06a9",
   "metadata": {},
   "source": [
    "## Part 1: Experiment interaction with Gtihub MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be03678",
   "metadata": {},
   "source": [
    "#### Example: Run GitHub MCP server locally in Docker\n",
    "The following code loads environment settings, spins up an OpenAI chat client, and launches GitHub’s MCP server inside Docker so the agent can call GitHub tools.\n",
    "\n",
    "dotenv pulls in API keys and MCP settings from .env.\n",
    "OpenAIChatClient is configured with your custom base URL/model so every MCP call uses that backend.\n",
    "\n",
    "The MCP tool definition wraps docker run; it injects the GitHub PAT plus the list of toolsets the server should expose.\n",
    "await github_mcp.connect() starts the Docker container and establishes the socket so subsequent ChatAgent runs can invoke GitHub functions (repos, PRs, issues, etc.) through the MCP layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub MCP connected\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import MCPStdioTool, ChatAgent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "chat_client = OpenAIChatClient(api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_PAT_TOKEN\")\n",
    "GITHUB_REPO = os.getenv(\"GITHUB_REPO\")\n",
    "GITHUB_OWNER = os.getenv(\"GITHUB_OWNER\")\n",
    "TARGET_PR_NUMBER = os.getenv(\"TARGET_PR_NUMBER\")\n",
    "# Specify the toolsets we want. There are far more, but only these are needed for this example.\n",
    "# And we don't want to bloat the agent's context with unnecessary tools.\n",
    "toolsets = \"context,pull_requests\" \n",
    "\n",
    "\n",
    "github_mcp = MCPStdioTool(\n",
    "    name=\"GitHubMCP\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\", \"-i\", \"--rm\",\n",
    "        \"-e\", f\"GITHUB_PERSONAL_ACCESS_TOKEN={GITHUB_TOKEN}\", \n",
    "        f\"-e\", f\"GITHUB_TOOLSETS={toolsets}\",\n",
    "        \"ghcr.io/github/github-mcp-server\"\n",
    "    ],\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "await github_mcp.connect()\n",
    "print(\"GitHub MCP connected\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef2837",
   "metadata": {},
   "source": [
    "### Example: List all available github mcp server tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7736338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions available in GitHub MCP (13):\n",
      "add_comment_to_pending_review\n",
      "create_pull_request\n",
      "get_me\n",
      "get_team_members\n",
      "get_teams\n",
      "list_pull_requests\n",
      "merge_pull_request\n",
      "pull_request_read\n",
      "pull_request_review_write\n",
      "request_copilot_review\n",
      "search_pull_requests\n",
      "update_pull_request\n",
      "update_pull_request_branch\n"
     ]
    }
   ],
   "source": [
    "print(f\"Functions available in GitHub MCP ({len(github_mcp.functions)}):\")\n",
    "for elem in github_mcp.functions:\n",
    "    print(elem.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71486542",
   "metadata": {},
   "source": [
    "### Example: Write comment to a pull request using Github's MCP server\n",
    "\n",
    "This block wires the GitHub MCP tools into a task‑specific agent that leaves a review comment on a pull request.\n",
    "\n",
    "all_tools = [*github_mcp.functions] expands every capability exposed by the connected MCP server (issues, PR reviews, etc.).\n",
    "\n",
    "The instructions string plays system prompt: the agent must operate only on iuf26/workshop-project-detect-secrets-in-repo and reply with SUCCESS or FAILURE.\n",
    "\n",
    "ChatAgent binds those instructions, the shared chat_client, and the MCP tool list into a named agent (ResearchAgent).\n",
    "\n",
    "The await agent.run(...) call triggers one conversational turn where the agent visits PR #1, starts a review if needed, and posts the requested comment on leaky_sample.py line 6; the printed result is just SUCCESS or FAILURE + reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [*github_mcp.functions]\n",
    "instructions = f\"\"\"\n",
    "You are a helpful assistant that helps me write comments to the '{GITHUB_REPO}' github repository with OWNER '{GITHUB_OWNER}'. \n",
    "As a response only return 'SUCCESS' if operation succeeded and otherwise return 'FAILURE' and reason for failure.\n",
    "If you get errors while attempting to write the comment, please attempt first to work around it (unless there is no way to do so).\n",
    "\"\"\"\n",
    "agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"ResearchAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await agent.run(\n",
    "    \"I would like to add the 'please remove this secret number 12 9 November'\" \\\n",
    "    \" comment to the pull request number 1 to the 'leaky_sample.py' file at line number 12. \" \\\n",
    "    \"If there is no review started for the viewer please do create it.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1ccf7",
   "metadata": {},
   "source": [
    "### Example: Retrieve all files from a PR using GitHub MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/flaviusfetean/workshop-detect_secrets/blob/feat/add_secrets/leaky_sample.py\n"
     ]
    }
   ],
   "source": [
    "from domain.models import PRFileList\n",
    "all_tools = [*github_mcp.functions]\n",
    "instructions = f\"\"\"\n",
    "You are a helpful assistant. Retrieve all files included in an open pull request from the GitHub repository '{GITHUB_OWNER}/{GITHUB_REPO}'.\n",
    "Respond only with a list of direct links (URLs) to the files changed or added in the pull request — no explanations or additional text.\n",
    "\"\"\"\n",
    "github_pr_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"PullRequestAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await github_pr_agent.run(\"Get me all the files involved in the PR with number 1.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d4519",
   "metadata": {},
   "source": [
    "We can also add Structured output to the chat client by specifying the desired output format in order to have a readily available object that we can use without parsing it ourselves, and we will know for sure that the structure is correct because it will be reinforced by the OpenAI server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28919e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured result: files=[PRFileInfo(source_file='leaky_sample.py', pull_request_number='1', source_branch='feat/add_secrets', repo='workshop-detect_secrets', repo_owner='flaviusfetean')]\n"
     ]
    }
   ],
   "source": [
    "from domain.models import PRFileList\n",
    "instructions = f\"\"\"\n",
    "You are a helpful assistant. Retrieve all files included in the open pull request from the GitHub repository '{GITHUB_OWNER}/{GITHUB_REPO}'.\n",
    "\"\"\"\n",
    "github_pr_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"PullRequestAgent\",\n",
    "    tools=all_tools, \n",
    "    response_format=PRFileList\n",
    " )\n",
    "# Extract with structured output\n",
    "result_structured = await github_pr_agent.run(\n",
    "    \"Get me all the files involved in the PR with number 1.\",\n",
    "    response_model=PRFileList\n",
    ")\n",
    "print(\"Structured result:\", result_structured.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74eac9",
   "metadata": {},
   "source": [
    "## Part 2: Implement agentic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb5990",
   "metadata": {},
   "source": [
    "### Define Chunk processing research agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6b45",
   "metadata": {},
   "source": [
    "### Split the files in chunk\n",
    "First, we need a method to split the file in the PR into chunks, as we don't want to fit an entire file into the context of the Agent.\n",
    "\n",
    "We can define the chunks whatever we like. Here, we define a chunk as a continuous block of 10 lines.\n",
    "But ideally, we want to keep logic intact, so a better approach would be to use more complex logic and not break multi-line statements or functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "def split_file_by_newlines(\n",
    "    file_path: str,\n",
    "    newlines_per_chunk: int,\n",
    "    pull_request_number: str = \"\",\n",
    "    repo: str = \"\",\n",
    "    repo_owner: str = \"\",\n",
    ") -> List[Dict]:\n",
    "    \"\"\" \n",
    "    Split a text file into chunks containing a fixed number of newline separators.\n",
    "    - Normalizes all line endings to '\\n' first.\n",
    "    - `original_lines_interval` is 1-based and inclusive.\n",
    "    - If the last chunk has fewer lines (fewer '\\n' separators), it's still included.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"http\" in file_path:\n",
    "        # If it's a web URL and not a local file, fetch the content\n",
    "        import requests\n",
    "        \n",
    "        filepath_github_raw = file_path.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "\n",
    "        r = requests.get(filepath_github_raw)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        text = r.text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "        original_file = file_path.split(\"/\")[-1]\n",
    "    else:\n",
    "        p = Path(file_path)\n",
    "        original_file = p.name\n",
    "\n",
    "        # Normalize all newlines to '\\n' to ensure consistent splitting\n",
    "        text = p.read_text(encoding=\"utf-8\", errors=\"replace\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # Split strictly by '\\n'\n",
    "    lines = text.split(\"\\n\")  # newline characters are removed by split\n",
    "    total_lines = len(lines)\n",
    "\n",
    "    chunks: List[Dict] = []\n",
    "\n",
    "    # Step through in blocks of `newlines_per_chunk` lines\n",
    "    for i in range(0, total_lines, newlines_per_chunk):\n",
    "        block = lines[i : i + newlines_per_chunk]\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        # Reconstruct the chunk string with '\\n' between lines.\n",
    "        # IMPORTANT: we DO NOT append a trailing '\\n' at the end of the chunk.\n",
    "        chunk_text = \"\\n\".join(block)\n",
    "\n",
    "        # 1-based line numbers for the original interval\n",
    "        start_line = i + 1\n",
    "        end_line = i + len(block)\n",
    "\n",
    "        chunks.append({\n",
    "            \"chunk\": chunk_text,\n",
    "            \"original_lines_interval\": [start_line, end_line],\n",
    "            \"original_file\": original_file,\n",
    "            \"pull_request_number\": pull_request_number,\n",
    "            \"repo\": repo,\n",
    "            \"repo_owner\": repo_owner,\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522e7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_chunks = split_file_by_newlines(\"samples/leaky_sample.py\",10,\"1\",repo=\"workshop-detect-secrets-in-repo\",repo_owner=\"iuf26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5569bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# leaky_sample.py\n",
      "# ⚠️ FAKE CREDENTIALS FOR TESTING ONLY. NONE OF THESE WORK.\n",
      "# This file intentionally contains strings that *look like* secrets so you can\n",
      "# test detectors, LLMs, and CI scanners. Do\n"
     ]
    }
   ],
   "source": [
    "input_test_chunks_from_url = split_file_by_newlines(\"https://raw.githubusercontent.com/flaviusfetean/workshop-detect_secrets/feat/add_secrets/leaky_sample.py\",10,\"1\",repo=\"workshop-detect_secrets\",repo_owner=\"flaviusfetean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b844cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "from domain.models import TextChunk\n",
    "\n",
    "NAMESPACE = uuid.UUID(\"876de125-4386-442b-9e88-d40dfbbb301d\")  # pick once & keep\n",
    "def stable_uuid(s: str) -> str:\n",
    "    s = s.strip().lower()  # normalize to avoid accidental mismatches\n",
    "    return str(uuid.uuid5(NAMESPACE, s))\n",
    "\n",
    "def shard_for_chunk(chunk: TextChunk, total_agents: int) -> int:\n",
    "    \"\"\"\n",
    "    Pick which worker (0..total_agents-1) should handle this chunk.\n",
    "\n",
    "    How it works (in plain words):\n",
    "    - Build a key from the file name and line range (e.g., \"app.py|120|180\").\n",
    "    - Hash that key with SHA-256 (gives a big, stable number).\n",
    "    - Take that number modulo total_agents to get a shard index.\n",
    "\n",
    "    Inputs:\n",
    "    - chunk: has `source_file: str` and `line_span: (start:int, end:int)`.\n",
    "    - total_agents: number of workers; must be >= 1.\n",
    "\n",
    "    Guarantees:\n",
    "    - Same chunk → same shard index (deterministic).\n",
    "    - Result r is an int with 0 <= r < total_agents.\n",
    "\n",
    "    Example:\n",
    "    >> shard_for_chunk(TextChunk(source_file=\"a.py\", line_span=(10, 30)), total_agents=3)\n",
    "    2\n",
    "    \"\"\"\n",
    "    h = hashlib.sha256(f\"{chunk.source_file}|{chunk.line_span}\".encode()).digest()\n",
    "    return int.from_bytes(h[:4], \"big\") % total_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7dd73f",
   "metadata": {},
   "source": [
    "#### Perform necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85438cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from agent_framework import (\n",
    "    handler, Executor, ChatAgent, \n",
    "    ExecutorInvokedEvent, ExecutorCompletedEvent,\n",
    "    WorkflowEvent, WorkflowBuilder, WorkflowContext, \n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "from domain.models import (\n",
    "    TextChunk, PRFileList, PRFileInfo, LineComment, \n",
    "    SecretsDetectorExecutorResponse, EmptySecretsDetectorExecutorResponseFactory, \n",
    ")\n",
    "DETECTED_SECRETS_RESULT_KEY = \"detected_secrets\"\n",
    "\n",
    "class CustomResponseEvent(WorkflowEvent):\n",
    "    def __init__(self, result: list[SecretsDetectorExecutorResponse]):\n",
    "        super().__init__(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9385f5",
   "metadata": {},
   "source": [
    "#### Define the Executors\n",
    "We will begin by defining the executor which actually performs secret detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecretsDetectorExec(Executor):\n",
    "    agent: ChatAgent\n",
    "    agent_instruction = \"\"\"\n",
    "        <instruction role=\"system\">\n",
    "        You are a code-secrets detector. Given a text CHUNK (with \"\\n\" newlines) and its original line interval [START, END], return only a JSON array of findings. Flag lines that contain likely secrets (API keys/tokens, private keys, passwords, connection strings with creds, service-account JSON fields, auth headers) or PII (names paired with email/phone/IDs). Be precise; if unsure, don't flag. Ignore obvious placeholders.\n",
    "        </instruction>\n",
    "        <schema>\n",
    "        Output exactly:\n",
    "        [\n",
    "        { \"line_number\": <int original line>, \"comment\": \"<types comma-separated>. Please remove.\" }\n",
    "        ]\n",
    "        Return [] if nothing is found. No extra text.\n",
    "        </schema>\n",
    "        <procedure>\n",
    "        1) Split CHUNK by \"\\n\".\n",
    "        2) For each line i (1-based), assess for secrets/PII using field names and context (e.g., \"api_key\", \"token\", \"password\", \"private_key\", DSN with user:pass, \"Authorization: Bearer ...\", service-account fields like private_key_id/private_key).\n",
    "        3) If flagged, compute original line_number = START + i - 1.\n",
    "        4) Emit JSON as per <schema>, comments short, no code excerpts.\n",
    "        </procedure>\n",
    "        <example>\n",
    "        INPUT:\n",
    "        START=4, END=7\n",
    "        CHUNK:\n",
    "        print(\"ok\")\n",
    "        \"private_key_id\": \"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\",\n",
    "        print(\"done\")\n",
    "\n",
    "        OUTPUT:\n",
    "        [\n",
    "        { \"line_number\": 5, \"comment\": \"Private key identifier. Please remove.\" }\n",
    "        ]\n",
    "        </example>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_client: OpenAIChatClient,  my_shard: int, total_agents: int, id: str = \"secrets detector\"):\n",
    "        # Define the inner agent which will do the secrets detection\n",
    "        #TODO: Here comes the code ;)\n",
    "        return\n",
    "    \n",
    "    def create_prompt_from_chunk(self, chunk: TextChunk):\n",
    "        prompt = f\"\"\"\n",
    "            Please investigate and detect secrets existent in the chunk taken from the line intervals of the file {chunk.source_file}.\n",
    "            INPUT\n",
    "            START={chunk.line_span[0]}, END={chunk.line_span[1]}\n",
    "            CHUNK:\n",
    "            {chunk.text}\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "    @handler\n",
    "    async def run(self, chunk: TextChunk,ctx: WorkflowContext[SecretsDetectorExecutorResponse]) -> None:\n",
    "        #TODO: Here comes the code ;)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13f701",
   "metadata": {},
   "source": [
    "We then define the executor which gathers the PR code and sends it to the secrets detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunksExporterExec(Executor):\n",
    "    agent_instructions = f\"\"\"\n",
    "        You are a helpful assistant. Retrieve all files included in an open pull request from the GitHub repository '{GITHUB_OWNER}/{GITHUB_REPO}'.\n",
    "        Respond only with a list of direct links (URLs) to the files changed or added in the pull request along with the necessary extra information (owner, repo, branch).\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, id, github_mcp_server, chat_client: OpenAIChatClient):\n",
    "        #TODO: Here comes the code ;)\n",
    "        return\n",
    "\n",
    "    @handler\n",
    "    async def run(self, _: str,ctx: WorkflowContext[TextChunk]) -> None:\n",
    "        #TODO: Here comes the code ;)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca5c21",
   "metadata": {},
   "source": [
    "We then define the executor which will aggregate the results of the findings and make the actual calls to post the comments on the PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6263a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunksAgregatorExec(Executor):\n",
    "\n",
    "    def __init__(self, id, github_mcp_server):\n",
    "         #TODO: Here comes the code ;)\n",
    "         return\n",
    "    \n",
    "    async def _call_github_mcp_client(self, detected_secret: SecretsDetectorExecutorResponse, line_comment: LineComment):\n",
    "        #TODO: Here comes the code ;)\n",
    "        return\n",
    "\n",
    "    @handler\n",
    "    async def run(self, detected_secrets: list[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[None]) -> None:\n",
    "        #TODO: Here comes the code ;)\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea32faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.2 (20251019.1705)\n",
       " -->\n",
       "<!-- Title: Workflow Pages: 1 -->\n",
       "<svg width=\"368pt\" height=\"265pt\"\n",
       " viewBox=\"0.00 0.00 368.00 265.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 261)\">\n",
       "<title>Workflow</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-261 364.25,-261 364.25,4 -4,4\"/>\n",
       "<!-- ChunkExporterAgent -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>ChunkExporterAgent</title>\n",
       "<polygon fill=\"lightgreen\" stroke=\"black\" points=\"246.25,-257 114,-257 114,-216 246.25,-216 246.25,-257\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"180.12\" y=\"-239.7\" font-family=\"Times,serif\" font-size=\"14.00\">ChunkExporterAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"180.12\" y=\"-223.2\" font-family=\"Times,serif\" font-size=\"14.00\">(Start)</text>\n",
       "</g>\n",
       "<!-- SecretsDetector1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>SecretsDetector1</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"108.25,-180 0,-180 0,-144 108.25,-144 108.25,-180\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.12\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">SecretsDetector1</text>\n",
       "</g>\n",
       "<!-- ChunkExporterAgent&#45;&gt;SecretsDetector1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>ChunkExporterAgent&#45;&gt;SecretsDetector1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.69,-215.69C129.61,-206.44 110.38,-195.37 93.71,-185.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.28,-180.93 96.19,-182.01 88.56,-182.81 93.95,-185.91 93.95,-185.91 93.95,-185.91 88.56,-182.81 91.7,-189.81 85.28,-180.93\"/>\n",
       "</g>\n",
       "<!-- SecretsDetector2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>SecretsDetector2</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"234.25,-180 126,-180 126,-144 234.25,-144 234.25,-180\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"180.12\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">SecretsDetector2</text>\n",
       "</g>\n",
       "<!-- ChunkExporterAgent&#45;&gt;SecretsDetector2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>ChunkExporterAgent&#45;&gt;SecretsDetector2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.12,-215.69C180.12,-208.17 180.12,-199.44 180.12,-191.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.13,-181.54 184.63,-191.54 180.13,-185.32 180.13,-191.54 180.13,-191.54 180.13,-191.54 180.13,-185.32 175.63,-191.54 180.13,-181.54\"/>\n",
       "</g>\n",
       "<!-- SecretsDetector3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>SecretsDetector3</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"360.25,-180 252,-180 252,-144 360.25,-144 360.25,-180\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"306.12\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">SecretsDetector3</text>\n",
       "</g>\n",
       "<!-- ChunkExporterAgent&#45;&gt;SecretsDetector3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>ChunkExporterAgent&#45;&gt;SecretsDetector3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.56,-215.69C230.64,-206.44 249.87,-195.37 266.54,-185.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.97,-180.93 268.55,-189.81 271.69,-182.81 266.3,-185.91 266.3,-185.91 266.3,-185.91 271.69,-182.81 264.06,-182.01 274.97,-180.93\"/>\n",
       "</g>\n",
       "<!-- fan_in::ChunksAgregatorAgent::e1432546 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>fan_in::ChunksAgregatorAgent::e1432546</title>\n",
       "<ellipse fill=\"#eedd82\" stroke=\"black\" cx=\"180.12\" cy=\"-90\" rx=\"32.93\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"180.12\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">fan&#45;in</text>\n",
       "</g>\n",
       "<!-- SecretsDetector1&#45;&gt;fan_in::ChunksAgregatorAgent::e1432546 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>SecretsDetector1&#45;&gt;fan_in::ChunksAgregatorAgent::e1432546</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.6,-143.52C104.63,-132.94 128.83,-119.5 147.98,-108.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.69,-104.02 150.13,-112.81 153.38,-105.86 147.95,-108.88 147.95,-108.88 147.95,-108.88 153.38,-105.86 145.76,-104.94 156.69,-104.02\"/>\n",
       "</g>\n",
       "<!-- SecretsDetector2&#45;&gt;fan_in::ChunksAgregatorAgent::e1432546 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>SecretsDetector2&#45;&gt;fan_in::ChunksAgregatorAgent::e1432546</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.12,-143.7C180.12,-136.32 180.12,-127.52 180.12,-119.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.13,-109.32 184.63,-119.32 180.13,-113.1 180.13,-119.32 180.13,-119.32 180.13,-119.32 180.13,-113.1 175.63,-119.32 180.13,-109.32\"/>\n",
       "</g>\n",
       "<!-- SecretsDetector3&#45;&gt;fan_in::ChunksAgregatorAgent::e1432546 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>SecretsDetector3&#45;&gt;fan_in::ChunksAgregatorAgent::e1432546</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274.65,-143.52C255.62,-132.94 231.42,-119.5 212.27,-108.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"203.56,-104.02 214.49,-104.94 206.87,-105.86 212.3,-108.88 212.3,-108.88 212.3,-108.88 206.87,-105.86 210.12,-112.81 203.56,-104.02\"/>\n",
       "</g>\n",
       "<!-- ChunksAgregatorAgent -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>ChunksAgregatorAgent</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"252.62,-36 107.62,-36 107.62,0 252.62,0 252.62,-36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"180.12\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">ChunksAgregatorAgent</text>\n",
       "</g>\n",
       "<!-- fan_in::ChunksAgregatorAgent::e1432546&#45;&gt;ChunksAgregatorAgent -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>fan_in::ChunksAgregatorAgent::e1432546&#45;&gt;ChunksAgregatorAgent</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.12,-71.7C180.12,-64.32 180.12,-55.52 180.12,-47.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.13,-37.32 184.63,-47.32 180.13,-41.1 180.13,-47.32 180.13,-47.32 180.13,-47.32 180.13,-41.1 175.63,-47.32 180.13,-37.32\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x113985d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent_framework import WorkflowViz\n",
    "#TODO: Here comes the code ;)\n",
    "viz = WorkflowViz(workflow)\n",
    "try:\n",
    "    from graphviz import Source\n",
    "    from IPython.display import display\n",
    "    src = Source(viz.to_digraph())\n",
    "    display(src)\n",
    "except Exception as e:\n",
    "    print(f\"Error rendering diagram: {e}\")\n",
    "    print(viz.to_mermaid())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf11f0",
   "metadata": {},
   "source": [
    "#### Visualize workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68af43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in PR: ['leaky_sample.py']\n",
      "# leaky_sample.py\n",
      "# ⚠️ FAKE CREDENTIALS FOR TESTING ONLY. NONE OF THESE WORK.\n",
      "# This file intentionally contains strings that *look like* secrets so you can\n",
      "# test detectors, LLMs, and CI scanners. Do\n",
      "Starting ChunkExporterAgent\n",
      "Completed ChunkExporterAgent: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Adding comment for file 'leaky_sample.py' at line 41\n",
      "Starting ChunksAgregatorAgent\n",
      "Adding comment for file 'leaky_sample.py' at line 42\n",
      "Adding comment for file 'leaky_sample.py' at line 43\n",
      "Adding comment for file 'leaky_sample.py' at line 44\n",
      "Adding comment for file 'leaky_sample.py' at line 45\n",
      "Adding comment for file 'leaky_sample.py' at line 46\n"
     ]
    }
   ],
   "source": [
    "async for event in workflow.run_stream(\"\"):\n",
    "    #TODO: Here comes the code ;)\n",
    "    return\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-demo-z2j_d0w_-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
